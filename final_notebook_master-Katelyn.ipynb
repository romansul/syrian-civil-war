{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Casualties and Migration in the Syrian Civil War"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "***\n",
    "\n",
    "In 2011, five weeks into the civil demonstrations against the Syrian government, secret police forces detained and tortured fifteen students who had spray painted an anti-government statement on the walls of their school. They would be released weeks later in an effort to quell the rising civil unrest in the province. In the wake of the hundreds of other demonstrators who were killed or disappeared, this action was too little and too late to stop the tide of the civil war. Demonstrations turned to protest turned to armed conflict and the rest is history.\n",
    "\n",
    "The war would go on to spawn both the largest refugee crisis and one of the deadliest conflicts in modern history. As of 2019, there are over 6 million Syrian refugees and another 6 million internally displaced people in a country with a pre-war population of around 24 million (UNHCR, 2018). The regime's efforts to prevent accurate information from leaving the country has made it nearly impossible to estimate the number of casualties that have occured in that time. Current estimates range from 300,000 to 600,000 killed depending on the source.\n",
    "\n",
    "The link between the flow of violence within the country and the flow of asylum seekers out of the country should be apparent to anyone who is aware of the war. Yet a growing sentiment among residents in host countries is that a large portion of asylum seekers from Syria are actually economic migrants, who are using the conflict as a means of gaining entry into the European Union and access to generous social programs.\n",
    "\n",
    "We believe that violence is the most important predictor of migration of Syrian refugees; however, while this argument may be generally accepted, there is great difficulty in proving this relationship for certain. We hope to answer this question using reported casualty data to see whether there is a correlation between violence in a given province and a subsequent increase in the amount of asylum seekers across all host countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project\n",
    "***\n",
    "\n",
    "Our project can be organized into three distinct portions:\n",
    "\n",
    "1. Data Scraping\n",
    "2. Data Wrangling\n",
    "3. Data Visualization\n",
    "\n",
    "Our goal is to create a dataset for casualty information a refugee data, clean and structure the dataset for easier queying, and visualize the data to provide more insights into the questions we pose above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping\n",
    "***\n",
    "\n",
    "There are multiple sources that could be used for casualty information (list here). We will leave the three datasets for now, and focus on the VDC and CSR datasets because they provide their data is table elements that make it easy for us to scrape and organize our dataframes for analysis.\n",
    "\n",
    "We will now go through the process of scraping and creating the inital forms of these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casualty Data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VDC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Violations Documentation Center](http://www.vdc-sy.info/) has been recording casualty data since June 2011. It is likely the most detailed and complete (in terms of metadata) data source of casualties that is publicly accessible.\n",
    "\n",
    "They provide their data with a user interface that will query their database using parameter the user defines. This interface will provide this information:\n",
    "\n",
    "- `Name                  - Full name in English`\n",
    "- `Status                - Civilian, non-civilian, or military status of deceased`\n",
    "- `Sex                   - Whether deceased is an Adult or Minor and Male or Female`\n",
    "- `Province              - One of the 14 Provinces of Syria`\n",
    "- `Area \\ Place of Birth - Various locations that can be Provinces/Subdistricts/Towns`\n",
    "- `Date of death         - self explanatory`\n",
    "- `Cause of death        - self explanatory`\n",
    "- `Actors                - groups involved in the casualty`\n",
    "\n",
    "Each entry is associated with a unique identifier, which is an integer between 0 and 250,000. Clicking on the name of the entry will lead the user to another page that provides the unique identifier number and other data that is not displayed on the main page. We will avoid describing this detail for now, since most of this data is not used in the final product.\n",
    "\n",
    "We will describe the full process we used to scrape all details from this website as well as the detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_recent():\n",
    "    first_page = 'http://www.vdc-sy.info/index.php/en/martyrs/1/c29ydGJ5PWEua2lsbGVkX2RhdGV8c29ydGRpcj1ERVNDfGFwcHJvdmVkPXZpc2libGV8ZXh0cmFkaXNwbGF5PTB8'\n",
    "    \n",
    "    # This is the format of the links that give us the unique identfiers\n",
    "    pattern    = re.compile('\\/index\\.php\\/en\\/details\\/martyrs\\/.')\n",
    "\n",
    "    # We want to establish a randomized user agent and Tor node to avoid detection\n",
    "    ua         = UserAgent()\n",
    "    headers    = {'User-Agent': ua.random}\n",
    "    tor        = TorRequest(password = 'commonhorse')\n",
    "    \n",
    "    try:\n",
    "        response = tor.get(first_page, headers=headers)\n",
    "        content  = bs(response.text, 'html.parser')\n",
    "        \n",
    "        # This list comprehension grabs all unique identifiers in string format for all links that match\n",
    "        # our regex pattern from above\n",
    "        links    = {link['href'][30:] for link in content.find_all('a', href = True) if pattern.match(link['href'])} \n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Provided a list of unique identifiers in string fromat, scrapes details and saves each entry \n",
    "as an idividual dataframe that represents one person.\n",
    "'''\n",
    "\n",
    "def scrape_details(uid, tor, headers):\n",
    "    cols = []\n",
    "    vals = []\n",
    "\n",
    "    url  = 'http://www.vdc-sy.info/index.php/en/details/martyrs/' + uid\n",
    "    \n",
    "    # Headers will provide the UserAgent to use when getting response\n",
    "    # Makes the request using a TorRequest object passed in\n",
    "    page = tor.get(url, headers = headers).text\n",
    "    page = bs(page, 'html.parser')\n",
    "    \n",
    "    # Grabs the relevant table info and all rows in it\n",
    "    table = page.find('table', attrs = {'class':'peopleListing'})\n",
    "    rows  = table.find_all('tr')\n",
    "\n",
    "    for row in rows:\n",
    "        data = row.find_all('td')\n",
    "\n",
    "        # All data without only 2 data values\n",
    "        # are not data we are looking for\n",
    "        if len(data) != 2:\n",
    "            continue\n",
    "\n",
    "        # data[0] corresponds to the row label/column\n",
    "        cols.append(data[0].text)\n",
    "        \n",
    "        # Values need to appended differently for image rows \n",
    "        if data[1].find('img') is not None:\n",
    "            vals.append(data[1].find('img')['src'])\n",
    "        else:\n",
    "            vals.append(data[1].text)\n",
    "\n",
    "    # Adds the uid to the dataframe\n",
    "    cols.append('uid')\n",
    "    vals.append(uid)\n",
    "\n",
    "    # Creates and saves dataframe\n",
    "    person = pd.DataFrame([vals], columns = cols, dtype=str)\n",
    "\n",
    "    save(person, os.path.join('person_dfs', uid))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each detailed page has a different number of columns depending on the metadata associated with that entry, so we will now have to combine all the dataframes. Pandas requires that columns have unique names, so we have to rename all duplicate columns using this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_dup_cols(dataframe):\n",
    "    cols = pd.Series(dataframe.columns)\n",
    "  \n",
    "    for dup in dataframe.columns.get_duplicates(): \n",
    "        cols[dataframe.columns.get_loc(dup)] = [dup + '_' + str(d_idx) if d_idx != 0 else dup for d_idx in range(dataframe.columns.get_loc(dup).sum())]\n",
    "   \n",
    "    dataframe.columns = cols\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now given a list of dataframes we can return a combined dataframe that retains all column data and saves that file as vdc_df and saves any failed dataframes as failed_vdc_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes(dataframes):\n",
    "    failed_dataframes = []\n",
    "    combined          = pd.DataFrame()\n",
    "\n",
    "    current = 0\n",
    "    num     = len(dataframes)\n",
    "\n",
    "    for df in dataframes:\n",
    "        try:\n",
    "            combined = pd.concat([combined, df], axis = 0)\n",
    "            print(f'{counter} / {num} people processed in combine_dataframes().')\n",
    "            counter += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            failed_dataframes.append(df)\n",
    "            print('Failed')\n",
    "            counter += 1\n",
    "\n",
    "    save(combined, 'vdc_df')\n",
    "    save(failed_dataframes, 'failed_vdc_df')\n",
    "\n",
    "    print('\\n\\nSuccess: ', len(dataframes) - len(failed_dataframes))\n",
    "    print('Failed: ', len(failed_dataframes))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, adding this all together. We will now:\n",
    "\n",
    "1. Build a list of unique identifiers by scraping the query page for the VDC database using scrape_recent()\n",
    "\n",
    "2. Scrape the detailed information provided the list of unique ids from scrape_recent() using scrape_details, which gives us dataframes for each person.\n",
    "\n",
    "3. Combine those dataframes into one large dataset using combine_dataframes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids_to_scrape = scrape_recent()\n",
    "uids_scraped   = set()\n",
    "\n",
    "while len(uids_to_scrape) > 0:\n",
    "    uid = uids_to_scrape.pop()\n",
    "    \n",
    "    try:\n",
    "        ua         = UserAgent()\n",
    "        headers    = {'User-Agent': ua.random}\n",
    "        tor        = TorRequest(password = 'cmps184')\n",
    "        scrape_details(uid, tor, headers)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        helen___uids_to_scrape.append(uid)\n",
    "\n",
    "        ua         = UserAgent()\n",
    "        headers    = {'User-Agent': ua.random}\n",
    "        tor        = TorRequest(password = 'cmps184')\n",
    "        tor.reset_identity()\n",
    "\n",
    "        continue\n",
    "        \n",
    "    uids_scraped.add(uid)\n",
    "\n",
    "    save(uids_to_scrape, 'uids_to_scrape')\n",
    "    save(uids_scraped  , 'uids_scraped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dataframes = []\n",
    "\n",
    "for person_df in glob.glob(os.path.join('person_dfs', '*.pickle')):\n",
    "    list_of_dataframes.append(load(person_df))\n",
    "    \n",
    "combine_dataframes(list_of_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Syrian Center for Statistics and Research](https://csr-sy.org/) has been recording casualty data since March 2011. It has less information than the VDC dataset, but the location of death is more precise.\n",
    "\n",
    "They provide their data with a user interface that will query their database using parameter the user defines. This interface will provide this information:\n",
    "\n",
    "- `ID Number             - Arbitrary ID number`\n",
    "- `First Name            - First name in Arabic`\n",
    "- `Father Name           - Father's last name in Arabic`\n",
    "- `Last Name             - Last name in Arabic`\n",
    "- `Province              - One of the 14 Provinces of Syria`\n",
    "- `Town                  - Town where they died`\n",
    "- `Date of death         - self explanatory`\n",
    "\n",
    "If you looked at the code to scrape the VDC website, you'll see that there is no package for Tor or user agent. For some reason, this particular website was cautious about who was looking at their data as it blocked our multiple attempts of trying to scrape without cycling through IP addresses and user agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section contain all the libraries that must be imported in order to run the web scraping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for requesting content of a web page\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "\n",
    "# for regex\n",
    "# import re\n",
    "\n",
    "# for dataframe creation\n",
    "import pandas as pd\n",
    "\n",
    "# for not overwhelming server when scraping pages\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "# For a progress bar while scraping\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For saving files\n",
    "import pickle\n",
    "\n",
    "# For shuffling list\n",
    "import random\n",
    "\n",
    "# For Tor Requests\n",
    "from torrequest     import TorRequest\n",
    "\n",
    "# To cycle through useragents\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to not have to rescrape everything if one page fails, it is essential to have a pickle file that you can store your successfully scraped data and failed attempts in. Below is the code to create and load a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load functions for a pickle file\n",
    "def save(obj, name):\n",
    "    pickle.dump(obj, open(name + '.pickle', 'wb'))\n",
    "\n",
    "def load(name):\n",
    "    return pickle.load(open(name + '.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the url to start scraping CSR\n",
    "url = 'https://csr-sy.org/?l=1&sons=redirect&sequence=&name=&father_name=&surname=&age_from=0&age_to=120&gender=&born_state=&born_town=&career=&society_status=&sons_no=&medical_status=&incident_state=&incident_town=&incident_desc=3&incident_date_from=&incident_date_to=&incident_details=&trial=&trial_date_from=&trial_date_to=&id=182&ddate_from=&ddate_to=&rec=0'\n",
    "\n",
    "response = get(url)\n",
    "html_soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The website was odd in the sense that some pages at the end didn't contain any information about Syrian casualties. We found the last page that had any information and hard-coded the page number in. As you can see from the code below, 91900 was the last page to contain any useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of numbers used in shuffling through all the URLs\n",
    "numbers_url = [str(i) for i in range(0, 91901, 50)]\n",
    "\n",
    "# shuffling the numbers so that the website doesn't become suspicious of us\n",
    "random.shuffle(numbers_url)\n",
    "numbers_url = set(numbers_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the pickle files: the good, the bad, and the ugly\n",
    "data_list     = load('csr_data_list')\n",
    "failed_urls   = load('failed_urls')\n",
    "finished_urls = load('finished_urls')\n",
    "\n",
    "# removes the URL number if that corresponding page has been scraped successfully\n",
    "for url in finished_urls:\n",
    "    try:\n",
    "        numbers_url.remove(url)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# tqdm() creates a progress bar to see how far you are from finishing your task\n",
    "# scrapes the website in a random order while cycling through IP addresses and user agents\n",
    "for number_url in tqdm(numbers_url):\n",
    "    try:\n",
    "        # being cautious\n",
    "        sleep(randint(30,60))\n",
    "        ua         = UserAgent()\n",
    "        user_agent = ua.random\n",
    "        headers    = {'User-Agent': user_agent}\n",
    "        tor = TorRequest(password = 'commonhorse')\n",
    "        tor.reset_identity()\n",
    "        \n",
    "        url = 'https://csr-sy.org/?l=1&sons=redirect&sequence=&name=&father_name=&surname='        + \\\n",
    "                '&age_from=0&age_to=120&gender=&born_state=&born_town=&career=&society_status='    + \\\n",
    "                '&sons_no=&medical_status=&incident_state=&incident_town=&incident_desc=3'         + \\\n",
    "                '&incident_date_from=&incident_date_to=&incident_details=&trial=&trial_date_from=' + \\\n",
    "                '&trial_date_to=&id=182&ddate_from=&ddate_to=&rec=' + number_url\n",
    "\n",
    "\n",
    "        response = tor.get(url, headers = headers)\n",
    "\n",
    "        html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        rows = html_soup.findAll('tr', {'title':'victim'})\n",
    "\n",
    "        # start scraping one page\n",
    "        for row in rows:\n",
    "            columns = row.findAll('td')\n",
    "\n",
    "            # saves the column data\n",
    "            for i in range(len(columns)):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    data_list[i - 1].append(columns[i].text)\n",
    "                    \n",
    "        finished_urls.append(number_url)\n",
    "        \n",
    "        # stores the successfully scraped data\n",
    "        save(data_list    , 'csr_data_list')\n",
    "        # stores the finished URL number\n",
    "        save(finished_urls, 'finished_urls')\n",
    "    \n",
    "    # pages that failed are stored in the pickle file failed_urls\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('\\nFailed on: ', number_url)\n",
    "        failed_urls.append(number_url)\n",
    "        save(failed_urls, 'failed_urls')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're done with all the pages, we want to convert our saved pickle file into a CSV file (to make loading in the data easier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a data frame\n",
    "victim_info = pd.DataFrame({\n",
    "    'victim_id'  : data_list[0],\n",
    "    'first_name' : data_list[1],\n",
    "    'father_name': data_list[2],\n",
    "    'last_name'  : data_list[3],\n",
    "    'province'   : data_list[4],\n",
    "    'town'       : data_list[5],\n",
    "    'date'       : data_list[6]    \n",
    "})\n",
    "\n",
    "# saves our file as a CSV file\n",
    "victim_info.to_csv(index=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refugee Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly Inflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [UN Refugee Agency [UNHCR]](http://popstats.unhcr.org/en/asylum_seekers_monthly) provides monthly refugee data in csv format with the following attributes:\n",
    "\n",
    "- `Years                 `\n",
    "- `Months                `\n",
    "- `Country / territory of asylum/residence                   `\n",
    "- `Origin  `\n",
    "\n",
    "The monthly data is from 1999-2018 and there are 38 European and 6 non-European countries provided about asylum applications. We selected data from the years 2011 - 2018 to focus on the the time frame of the Syrian Civil War which stared in March 15, 2011. You can download the csv file by selecting the following categories:\n",
    "- `Years: 2011-2018                 `\n",
    "- `Months: All months               `\n",
    "- `Country / territory of asylum/residence: All countries/territories                   `\n",
    "- `Origin: Syrian Arab Republic `\n",
    "\n",
    "The csv file is readily available so we did not have to do any further scraping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# load csv file into pandas dataframe\n",
    "refugee_month_df = pd.read_csv('2011-2018_monthly_refugee.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yearly Refugee Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [UN Refugee Agency [UNHCR]](https://data.world/unhcr/e2d5566d-d755-40dd-a63f-d4d298a9df1d/workspace/file?filename=unhcr-persons-of-concern-origin-syr-csv-1.csv) provides year-by-year data from 1968-2017 concerning refugee migrations and more population concerns originating from Syria. We can can access this data in csv format easily, however the link provided may ask the user to sign in with a dataworld account or  google/facebook profile. The dataset contains the following attributes:\n",
    "\n",
    "- `Year                 `\n",
    "- `Country / territory of asylum/residence                `\n",
    "- `Origin                   `\n",
    "- `Refugees (incl. refugee-like situations  `\n",
    "- `Asylum-seekers (pending cases)                 `\n",
    "- `Returned refugees               `\n",
    "- `Internally displaced persons (IDPs)                `\n",
    "- `Returned IDPs  `\n",
    "- `Stateless persons                 `\n",
    "- `Total Population `\n",
    "\n",
    "We are interested in selecting the following columns and filter our data frame accordingly:\n",
    "- `Year                 `\n",
    "- `Country / territory of asylum/residence                `\n",
    "- `Origin                   `\n",
    "- `Refugees (incl. refugee-like situations  `\n",
    "- `Asylum-seekers (pending cases)                 `\n",
    "- `Total Population `\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv file into pandas dataframe\n",
    "refugee_year_df = pd.read_csv('unhcr-persons-of-concern-origin-syr-csv-1.csv')\n",
    "\n",
    "# sort dataframe by ascending years\n",
    "refugee_year_df = refugee_year_df.sort_values('Year', ascending=True)\n",
    "\n",
    "# adjust index of dataframe\n",
    "refugee_year_df = refugee_year_df.reset_index()\n",
    "refugee_year_df = refugee_year_df.drop(refugee_df.index[0])\n",
    "refugee_year_df = refugee_year_df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter the dataset by limiting columns and the time between 2011 and 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the years we want\n",
    "years = ['2011', '2012', '2013', '2014', '2015','2016', '2017']\n",
    "\n",
    "refugee_subset = refugee_year_df[refugee_year_df['Year'].isin(years)]\n",
    "\n",
    "# reset index\n",
    "refugee_subset = refugee_subset.reset_index()\n",
    "\n",
    "# drop index column\n",
    "bad_cols = ['index','Origin','Returned refugees','Returned refugees',\n",
    "            'Internally displaced persons (IDPs)','Returned IDPs',\n",
    "            'Stateless persons','Others of concern']\n",
    "refugee_subset = refugee_subset.drop(bad_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casualty Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VDC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the cell below to see what the dataset looks like without any modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdc_df = load('vdc_df')\n",
    "vdc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the added details we got from scraping everythign from the website are valuable for more detailed analysis, these particular columns will be what we will be focusing on with this project:\n",
    "\n",
    "- `Name                  `\n",
    "- `Status                `\n",
    "- `Sex                   `\n",
    "- `Province              `\n",
    "- `Area \\ Place of Birth `\n",
    "- `Date of death         `\n",
    "- `Cause of death        `\n",
    "- `Actors                `\n",
    "\n",
    "And we can create a dataframe we will use to do all of their data frame so that we are not modifying the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch = vdc_df[['Province',\n",
    "                  'Sex',\n",
    "                  'Status',\n",
    "                  'Date of death',\n",
    "                  'Cause of Death']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the `Sex` column, we can see that there is actually data about the person's minority status and age range, so we will create new columns to capture that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll first want to drop any rows that don't have this information\n",
    "scratch = scratch.dropna(subset=['Sex'])\n",
    "\n",
    "def check_age(row):\n",
    "    if 'Adult' in row['Sex']:\n",
    "        val = 'adult'\n",
    "    else:\n",
    "        val = 'minor'\n",
    "    return val\n",
    "\n",
    "scratch['age_cat'] = scratch.apply(check_age, axis=1)\n",
    "\n",
    "def check_sex(row):\n",
    "    if 'Male' in row['Sex']:\n",
    "        val = 'male'\n",
    "    else:\n",
    "        val = 'female'\n",
    "    return val\n",
    "\n",
    "scratch['sex'] = scratch.apply(check_sex, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the `Cause of Death` coolumn, we'll see that there is some reduntant categories, so we'll simplify these categories by remapping those values based on a dictionary mapping we show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_of_death_map = {'Chemical and toxic gases'         : 'Chemical Weapon',\n",
    "                      'Detention - Execution'            : 'Detention',\n",
    "                      'Detention - Torture'              : 'Detention',\n",
    "                      'Detention - Torture - Execution'  : 'Detention',\n",
    "                      'Explosion'                        : 'Explosion',\n",
    "                      'Field Execution'                  : 'Execution',\n",
    "                      'Kidnapping - Execution'           : 'Execution',\n",
    "                      'Kidnapping - Torture'             : 'Execution',\n",
    "                      'Kidnapping - Torture - Execution' : 'Execution',\n",
    "                      'Other'                            : 'Unknown'  ,\n",
    "                      'Shelling'                         : 'Shelling' ,\n",
    "                      'Shooting'                         : 'Shooting' ,\n",
    "                      'Siege'                            : 'Siege'    ,\n",
    "                      'Un-allowed to seek Medical help'  : 'Lack of Medical Access',\n",
    "                      'Unknown'                          : 'Unknown'  ,\n",
    "                      'Warplane shelling'                : 'Shelling' \n",
    "}\n",
    "\n",
    "def check_cause_of_death(row, mapping):\n",
    "    return mapping[row['Cause of Death']]\n",
    "\n",
    "scratch['cause_of_death'] = scratch.apply(check_cause_of_death,\n",
    "                                        args = (cause_of_death_map, ),\n",
    "                                        axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we can change the status column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_status(row):\n",
    "    if row['Status'] == 'Non-Civilian':\n",
    "        val = 'non_civilian'\n",
    "    elif row['Status'] == 'Civilian':\n",
    "        val = 'civilian'\n",
    "    else:\n",
    "        val = 'regime'\n",
    "    return val\n",
    "\n",
    "scratch['status'] = scratch.apply(check_status, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset is cleaner, we can drop columns that irrelevant to us, and rename the columns for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch = scratch[['Province',\n",
    "                  'sex',\n",
    "                  'status',\n",
    "                  'age_cat',\n",
    "                  'Date of death',\n",
    "                  'cause_of_death']].copy()\n",
    "\n",
    "scratch.columns = ['province', 'sex', 'status', 'age_cat','date_of_death', 'cause_of_death']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now drop any entries with unrecroded or icorrect dates of death and convert the time strings to python datetime objects.\n",
    "\n",
    "With all of those modifcations we can finally save this dataset as complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch = scratch[scratch['province'].isin(picked)]\n",
    "scratch = scratch[scratch['date_of_death'] != '0000-00-00']\n",
    "scratch = scratch[scratch['date_of_death'] != '1970-01-01']\n",
    "scratch['date_of_death'] = pd.to_datetime(scratch['date_of_death'])\n",
    "\n",
    "save(scratch, 'clean_vdc_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refugee Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly Inflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yearly Refugee Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotly requires country codes in order to plot countries. We found a csv file of country codes that work with Plotly on [Kaggle](https://www.kaggle.com/shep312/plotlycountrycodes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab country codes in order to use it with Plotly\n",
    "countries_df = pd.read_csv('plotly_countries_and_codes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We went through our refugee data and changed country names to make it compatible with the Plotly country names in order to join the two data frames. These are the countries we had to adjust.\n",
    "- `Venezuela (Bolivarian Republic of) -> Venezuela           `\n",
    "- `Czech Rep. -> Czech Republic `\n",
    "- `Iran (Islamic Rep. of) -> Iran`\n",
    "- `The former Yugoslav Republic of Macedonia -> Macedonia`\n",
    "- `Bolivia (Plurinational State of) -> Bolivia              `\n",
    "- `Dominican Rep. -> Dominican Republic`\n",
    "- `Rep. of Korea -> Korea, South  `\n",
    "- `South Sudan -> Sudan`\n",
    "- `Dem. Rep. of the Congo -> Congo, Democratic Republic of the                `\n",
    "- `Central African Rep. -> Central African Republic`\n",
    "- `United States of America -> United States `\n",
    "- `Sint Maarten (Dutch part) -> Sint Maarten`\n",
    "- `Serbia and Kosovo (S/RES/1244 (1999)) -> Serbia `\n",
    "- `Rep. of Moldova -> Moldova`\n",
    "- `Syrian Arab Rep. -> Syria`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace names in refugee_subse dataframe\n",
    "new_refugee_df = refugee_subset.replace({\n",
    "    'Venezuela (Bolivarian Republic of)':'Venezuela',\n",
    "    'Czech Rep.':'Czech Republic',\n",
    "    'Iran (Islamic Rep. of)':'Iran',\n",
    "    'The former Yugoslav Republic of Macedonia':'Macedonia',\n",
    "    'Bolivia (Plurinational State of)':'Bolivia',\n",
    "    'Dominican Rep.':'Dominican Republic',\n",
    "    'Rep. of Korea': 'Korea, South',\n",
    "    'United Rep. of Tanzania':'Tanzania',\n",
    "    'China, Hong Kong SAR':'Hong Kong',\n",
    "    'South Sudan':'Sudan',\n",
    "    'Dem. Rep. of the Congo':'Congo, Democratic Republic of the',\n",
    "    'Central African Rep.':'Central African Republic',\n",
    "    'United States of America':'United States',\n",
    "    'Sint Maarten (Dutch part)':'Sint Maarten',\n",
    "    'Serbia and Kosovo (S/RES/1244 (1999))':'Serbia',\n",
    "    'Rep. of Moldova':'Moldova',\n",
    "    'Syrian Arab Rep.':'Syria', \n",
    "    'Russian Federation':'Russia',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge refugee data with Plotly country codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the two tables together\n",
    "merged_df = new_refugee_df.set_index('Country / territory of asylum/residence').join(countries_df.set_index('COUNTRY'))\n",
    "\n",
    "# reset row index\n",
    "merged_df = merged_df.reset_index()\n",
    "\n",
    "# remove GDP column\n",
    "merged_df = merged_df.drop(['GDP (BILLIONS)'], axis=1)\n",
    "\n",
    "# rename index column to 'Country'\n",
    "merged_df.rename(columns={'index':'Country'}, inplace=True)\n",
    "\n",
    "# rearrange columns\n",
    "merged_df = merged_df[['CODE','Country','Year',\n",
    "                       'Refugees (incl. refugee-like situations)',\n",
    "                       'Asylum-seekers (pending cases)',\n",
    "                       'Total Population']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set contains NaN values and * for missing data. We need to change these to 0. We do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0\n",
    "\n",
    "filter_rows = ['Refugees (incl. refugee-like situations)','Asylum-seekers (pending cases)','Total Population']\n",
    "for i in filter_rows:\n",
    "    # Fill NaN values with 0\n",
    "    merged_df[i] = merged_df[i].fillna(0)\n",
    "    # remove * and convert values to int values\n",
    "    merged_df[i] = merged_df[i].apply(lambda x : 0 if x == '*' else int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data provided is cumulative, so we select the last year available which is 2017 to represent data from 2011-2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows where the refugee data is not 0\n",
    "new_total_df = merged_df[merged_df['Refugees (incl. refugee-like situations)'] != 0]\n",
    "\n",
    "year_df = new_total_df[new_total_df['Year'] == '2017']\n",
    "year_df = year_df.reset_index()\n",
    "year_df = year_df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the latitude and longitude for each country so we are using from ?????."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df = pd.read_csv('countries.csv')\n",
    "\n",
    "total_sum_df= year_df.set_index('Country').join(locations_df.set_index('name'))\n",
    "total_sum_df = total_sum_df.reset_index()\n",
    "total_sum_df = total_sum_df.drop(['country'], axis=1)\n",
    "total_sum_df.rename(columns={'index':'Country'}, inplace=True)\n",
    "# total_sum_df.iloc[26]['Country']\n",
    "\n",
    "total_sum_df.at[26,'CODE'] = 'CI'\n",
    "\n",
    "# # drop rows where CODE is none\n",
    "total_sum_df = total_sum_df.dropna(subset=['CODE','Refugees (incl. refugee-like situations)'])\n",
    "total_sum_df.to_csv('total_sum_refugee_data.csv',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Congo\n",
    "# total_sum_df.iloc[19]['latitude']  = -4.038333\n",
    "# total_sum_df.iloc[19]['longitude'] = 21.758664\n",
    "\n",
    "# # Macdeonia\n",
    "# total_sum_df.at[59,'latitude'] = 41.6086\n",
    "# total_sum_df.at[59,'latitude'] = 21.7453\n",
    "\n",
    "# # South Korea\n",
    "# total_sum_df.at[49, 'latitude'] = 35.9078\n",
    "# total_sum_df.at[49, 'longitude'] = 127.7669\n",
    "\n",
    "# # Côte d'Ivoire\n",
    "# total_sum_df.at[49, 'latitude'] = 7.539989\n",
    "# total_sum_df.at[49, 'longitude'] = -5.54708\n",
    "\n",
    "# total_sum_df.to_csv('total_sum_refugee_data_2.csv',index=False, header=True)\n",
    "\n",
    "# total_sum_df.iloc[19]['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>CODE</th>\n",
       "      <th>Year</th>\n",
       "      <th>Refugees (incl. refugee-like situations)</th>\n",
       "      <th>Asylum-seekers (pending cases)</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>TUR</td>\n",
       "      <td>2017</td>\n",
       "      <td>3424237</td>\n",
       "      <td>163</td>\n",
       "      <td>3424400</td>\n",
       "      <td>38.963745</td>\n",
       "      <td>35.243322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lebanon</td>\n",
       "      <td>LBN</td>\n",
       "      <td>2017</td>\n",
       "      <td>992127</td>\n",
       "      <td>8</td>\n",
       "      <td>994383</td>\n",
       "      <td>33.854721</td>\n",
       "      <td>35.862285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jordan</td>\n",
       "      <td>JOR</td>\n",
       "      <td>2017</td>\n",
       "      <td>653031</td>\n",
       "      <td>0</td>\n",
       "      <td>653031</td>\n",
       "      <td>30.585164</td>\n",
       "      <td>36.238414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Germany</td>\n",
       "      <td>DEU</td>\n",
       "      <td>2017</td>\n",
       "      <td>496674</td>\n",
       "      <td>70833</td>\n",
       "      <td>567507</td>\n",
       "      <td>51.165691</td>\n",
       "      <td>10.451526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iraq</td>\n",
       "      <td>IRQ</td>\n",
       "      <td>2017</td>\n",
       "      <td>247057</td>\n",
       "      <td>0</td>\n",
       "      <td>247057</td>\n",
       "      <td>33.223191</td>\n",
       "      <td>43.679291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>EGY</td>\n",
       "      <td>2017</td>\n",
       "      <td>126688</td>\n",
       "      <td>0</td>\n",
       "      <td>126688</td>\n",
       "      <td>26.820553</td>\n",
       "      <td>30.802498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>SWE</td>\n",
       "      <td>2017</td>\n",
       "      <td>103614</td>\n",
       "      <td>3531</td>\n",
       "      <td>107145</td>\n",
       "      <td>60.128161</td>\n",
       "      <td>18.643501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>2017</td>\n",
       "      <td>43888</td>\n",
       "      <td>3937</td>\n",
       "      <td>47825</td>\n",
       "      <td>47.516231</td>\n",
       "      <td>14.550072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2017</td>\n",
       "      <td>30851</td>\n",
       "      <td>668</td>\n",
       "      <td>31519</td>\n",
       "      <td>52.132633</td>\n",
       "      <td>5.291266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>DNK</td>\n",
       "      <td>2017</td>\n",
       "      <td>19221</td>\n",
       "      <td>285</td>\n",
       "      <td>19506</td>\n",
       "      <td>56.263920</td>\n",
       "      <td>9.501785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>BGR</td>\n",
       "      <td>2017</td>\n",
       "      <td>16549</td>\n",
       "      <td>407</td>\n",
       "      <td>16956</td>\n",
       "      <td>42.733883</td>\n",
       "      <td>25.485830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>ARM</td>\n",
       "      <td>2017</td>\n",
       "      <td>14680</td>\n",
       "      <td>12</td>\n",
       "      <td>14692</td>\n",
       "      <td>40.069099</td>\n",
       "      <td>45.038189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Greece</td>\n",
       "      <td>GRC</td>\n",
       "      <td>2017</td>\n",
       "      <td>13714</td>\n",
       "      <td>9605</td>\n",
       "      <td>23319</td>\n",
       "      <td>39.074208</td>\n",
       "      <td>21.824312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>CHE</td>\n",
       "      <td>2017</td>\n",
       "      <td>13639</td>\n",
       "      <td>3192</td>\n",
       "      <td>16831</td>\n",
       "      <td>46.818188</td>\n",
       "      <td>8.227512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2017</td>\n",
       "      <td>12520</td>\n",
       "      <td>2394</td>\n",
       "      <td>14914</td>\n",
       "      <td>46.227638</td>\n",
       "      <td>2.213749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Spain</td>\n",
       "      <td>ESP</td>\n",
       "      <td>2017</td>\n",
       "      <td>11752</td>\n",
       "      <td>2255</td>\n",
       "      <td>14007</td>\n",
       "      <td>40.463667</td>\n",
       "      <td>-3.749220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Norway</td>\n",
       "      <td>NOR</td>\n",
       "      <td>2017</td>\n",
       "      <td>11498</td>\n",
       "      <td>17</td>\n",
       "      <td>11515</td>\n",
       "      <td>60.472024</td>\n",
       "      <td>8.468946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sudan</td>\n",
       "      <td>SDN</td>\n",
       "      <td>2017</td>\n",
       "      <td>11240</td>\n",
       "      <td>439</td>\n",
       "      <td>11679</td>\n",
       "      <td>12.862807</td>\n",
       "      <td>30.217636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GBR</td>\n",
       "      <td>2017</td>\n",
       "      <td>9100</td>\n",
       "      <td>574</td>\n",
       "      <td>9674</td>\n",
       "      <td>55.378051</td>\n",
       "      <td>-3.435973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>BEL</td>\n",
       "      <td>2017</td>\n",
       "      <td>9080</td>\n",
       "      <td>1665</td>\n",
       "      <td>10745</td>\n",
       "      <td>50.503887</td>\n",
       "      <td>4.469936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>2017</td>\n",
       "      <td>7282</td>\n",
       "      <td>3358</td>\n",
       "      <td>10640</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>-95.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>CYP</td>\n",
       "      <td>2017</td>\n",
       "      <td>5274</td>\n",
       "      <td>1585</td>\n",
       "      <td>12859</td>\n",
       "      <td>35.126413</td>\n",
       "      <td>33.429859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Italy</td>\n",
       "      <td>ITA</td>\n",
       "      <td>2017</td>\n",
       "      <td>3618</td>\n",
       "      <td>1696</td>\n",
       "      <td>5314</td>\n",
       "      <td>41.871940</td>\n",
       "      <td>12.567380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>YEM</td>\n",
       "      <td>2017</td>\n",
       "      <td>3286</td>\n",
       "      <td>496</td>\n",
       "      <td>3782</td>\n",
       "      <td>15.552727</td>\n",
       "      <td>48.516388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Canada</td>\n",
       "      <td>CAN</td>\n",
       "      <td>2017</td>\n",
       "      <td>3095</td>\n",
       "      <td>806</td>\n",
       "      <td>3901</td>\n",
       "      <td>56.130366</td>\n",
       "      <td>-106.346771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Morocco</td>\n",
       "      <td>MAR</td>\n",
       "      <td>2017</td>\n",
       "      <td>2953</td>\n",
       "      <td>0</td>\n",
       "      <td>2953</td>\n",
       "      <td>31.791702</td>\n",
       "      <td>-7.092620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>BRA</td>\n",
       "      <td>2017</td>\n",
       "      <td>2905</td>\n",
       "      <td>4522</td>\n",
       "      <td>7427</td>\n",
       "      <td>-14.235004</td>\n",
       "      <td>-51.925280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Finland</td>\n",
       "      <td>FIN</td>\n",
       "      <td>2017</td>\n",
       "      <td>2370</td>\n",
       "      <td>133</td>\n",
       "      <td>2503</td>\n",
       "      <td>61.924110</td>\n",
       "      <td>25.748151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Romania</td>\n",
       "      <td>ROU</td>\n",
       "      <td>2017</td>\n",
       "      <td>2282</td>\n",
       "      <td>167</td>\n",
       "      <td>2449</td>\n",
       "      <td>45.943161</td>\n",
       "      <td>24.966760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Malta</td>\n",
       "      <td>MLT</td>\n",
       "      <td>2017</td>\n",
       "      <td>1289</td>\n",
       "      <td>251</td>\n",
       "      <td>1540</td>\n",
       "      <td>35.937496</td>\n",
       "      <td>14.375416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Ecuador</td>\n",
       "      <td>ECU</td>\n",
       "      <td>2017</td>\n",
       "      <td>39</td>\n",
       "      <td>115</td>\n",
       "      <td>154</td>\n",
       "      <td>-1.831239</td>\n",
       "      <td>-78.183406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Peru</td>\n",
       "      <td>PER</td>\n",
       "      <td>2017</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>-9.189967</td>\n",
       "      <td>-75.015152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>IDN</td>\n",
       "      <td>2017</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "      <td>-0.789275</td>\n",
       "      <td>113.921327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Qatar</td>\n",
       "      <td>QAT</td>\n",
       "      <td>2017</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>25.354826</td>\n",
       "      <td>51.183884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Liechtenstein</td>\n",
       "      <td>LIE</td>\n",
       "      <td>2017</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>47.166000</td>\n",
       "      <td>9.555373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>PAK</td>\n",
       "      <td>2017</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>30.375321</td>\n",
       "      <td>69.345116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>MEX</td>\n",
       "      <td>2017</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>23.634501</td>\n",
       "      <td>-102.552784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Slovakia</td>\n",
       "      <td>SVK</td>\n",
       "      <td>2017</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>48.669026</td>\n",
       "      <td>19.699024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>KAZ</td>\n",
       "      <td>2017</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>48.019573</td>\n",
       "      <td>66.923684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Cameroon</td>\n",
       "      <td>CMR</td>\n",
       "      <td>2017</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>7.369722</td>\n",
       "      <td>12.354722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>BIH</td>\n",
       "      <td>2017</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>43.915886</td>\n",
       "      <td>17.679076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>AZE</td>\n",
       "      <td>2017</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>40.143105</td>\n",
       "      <td>47.576927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Macedonia</td>\n",
       "      <td>MKD</td>\n",
       "      <td>2017</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>SAU</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>23.885942</td>\n",
       "      <td>45.079162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>LKA</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>7.873054</td>\n",
       "      <td>80.771797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Bolivia</td>\n",
       "      <td>BOL</td>\n",
       "      <td>2017</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>-16.290154</td>\n",
       "      <td>-63.588653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Côte d'Ivoire</td>\n",
       "      <td>CI</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>CRI</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>9.748917</td>\n",
       "      <td>-83.753428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>ETH</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>67</td>\n",
       "      <td>76</td>\n",
       "      <td>9.145000</td>\n",
       "      <td>40.489673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Djibouti</td>\n",
       "      <td>DJI</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11.825138</td>\n",
       "      <td>42.590275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Mali</td>\n",
       "      <td>MLI</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>17.570692</td>\n",
       "      <td>-3.996166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Congo, Democratic Republic of the</td>\n",
       "      <td>COD</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>COL</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4.570868</td>\n",
       "      <td>-74.297333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>5821</td>\n",
       "      <td>5829</td>\n",
       "      <td>28.033886</td>\n",
       "      <td>1.659626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Liberia</td>\n",
       "      <td>LBR</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>6.428055</td>\n",
       "      <td>-9.429499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Uganda</td>\n",
       "      <td>UGA</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>1.373333</td>\n",
       "      <td>32.290275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Benin</td>\n",
       "      <td>BEN</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9.307690</td>\n",
       "      <td>2.315834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Niger</td>\n",
       "      <td>NER</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17.607789</td>\n",
       "      <td>8.081666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Oman</td>\n",
       "      <td>OMN</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>21.512583</td>\n",
       "      <td>55.923255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>El Salvador</td>\n",
       "      <td>SLV</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13.794185</td>\n",
       "      <td>-88.896530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Country CODE  Year  \\\n",
       "0                               Turkey  TUR  2017   \n",
       "1                              Lebanon  LBN  2017   \n",
       "2                               Jordan  JOR  2017   \n",
       "3                              Germany  DEU  2017   \n",
       "4                                 Iraq  IRQ  2017   \n",
       "5                                Egypt  EGY  2017   \n",
       "6                               Sweden  SWE  2017   \n",
       "7                              Austria  AUT  2017   \n",
       "8                          Netherlands  NLD  2017   \n",
       "9                              Denmark  DNK  2017   \n",
       "10                            Bulgaria  BGR  2017   \n",
       "11                             Armenia  ARM  2017   \n",
       "12                              Greece  GRC  2017   \n",
       "13                         Switzerland  CHE  2017   \n",
       "14                              France  FRA  2017   \n",
       "15                               Spain  ESP  2017   \n",
       "16                              Norway  NOR  2017   \n",
       "17                               Sudan  SDN  2017   \n",
       "18                      United Kingdom  GBR  2017   \n",
       "19                             Belgium  BEL  2017   \n",
       "20                       United States  USA  2017   \n",
       "21                              Cyprus  CYP  2017   \n",
       "22                               Italy  ITA  2017   \n",
       "23                               Yemen  YEM  2017   \n",
       "24                              Canada  CAN  2017   \n",
       "25                             Morocco  MAR  2017   \n",
       "26                              Brazil  BRA  2017   \n",
       "27                             Finland  FIN  2017   \n",
       "28                             Romania  ROU  2017   \n",
       "29                               Malta  MLT  2017   \n",
       "..                                 ...  ...   ...   \n",
       "74                             Ecuador  ECU  2017   \n",
       "75                                Peru  PER  2017   \n",
       "76                           Indonesia  IDN  2017   \n",
       "77                               Qatar  QAT  2017   \n",
       "78                       Liechtenstein  LIE  2017   \n",
       "79                            Pakistan  PAK  2017   \n",
       "80                              Mexico  MEX  2017   \n",
       "81                            Slovakia  SVK  2017   \n",
       "82                          Kazakhstan  KAZ  2017   \n",
       "83                            Cameroon  CMR  2017   \n",
       "84              Bosnia and Herzegovina  BIH  2017   \n",
       "85                          Azerbaijan  AZE  2017   \n",
       "86                           Macedonia  MKD  2017   \n",
       "87                        Saudi Arabia  SAU  2017   \n",
       "88                           Sri Lanka  LKA  2017   \n",
       "89                             Bolivia  BOL  2017   \n",
       "90                       Côte d'Ivoire   CI  2017   \n",
       "91                          Costa Rica  CRI  2017   \n",
       "92                            Ethiopia  ETH  2017   \n",
       "93                            Djibouti  DJI  2017   \n",
       "94                                Mali  MLI  2017   \n",
       "95   Congo, Democratic Republic of the  COD  2017   \n",
       "96                            Colombia  COL  2017   \n",
       "97                             Algeria  DZA  2017   \n",
       "98                             Liberia  LBR  2017   \n",
       "99                              Uganda  UGA  2017   \n",
       "100                              Benin  BEN  2017   \n",
       "101                              Niger  NER  2017   \n",
       "102                               Oman  OMN  2017   \n",
       "103                        El Salvador  SLV  2017   \n",
       "\n",
       "     Refugees (incl. refugee-like situations)  Asylum-seekers (pending cases)  \\\n",
       "0                                     3424237                             163   \n",
       "1                                      992127                               8   \n",
       "2                                      653031                               0   \n",
       "3                                      496674                           70833   \n",
       "4                                      247057                               0   \n",
       "5                                      126688                               0   \n",
       "6                                      103614                            3531   \n",
       "7                                       43888                            3937   \n",
       "8                                       30851                             668   \n",
       "9                                       19221                             285   \n",
       "10                                      16549                             407   \n",
       "11                                      14680                              12   \n",
       "12                                      13714                            9605   \n",
       "13                                      13639                            3192   \n",
       "14                                      12520                            2394   \n",
       "15                                      11752                            2255   \n",
       "16                                      11498                              17   \n",
       "17                                      11240                             439   \n",
       "18                                       9100                             574   \n",
       "19                                       9080                            1665   \n",
       "20                                       7282                            3358   \n",
       "21                                       5274                            1585   \n",
       "22                                       3618                            1696   \n",
       "23                                       3286                             496   \n",
       "24                                       3095                             806   \n",
       "25                                       2953                               0   \n",
       "26                                       2905                            4522   \n",
       "27                                       2370                             133   \n",
       "28                                       2282                             167   \n",
       "29                                       1289                             251   \n",
       "..                                        ...                             ...   \n",
       "74                                         39                             115   \n",
       "75                                         38                               0   \n",
       "76                                         35                              27   \n",
       "77                                         34                               0   \n",
       "78                                         32                               0   \n",
       "79                                         29                               0   \n",
       "80                                         23                               0   \n",
       "81                                         17                               0   \n",
       "82                                         17                              23   \n",
       "83                                         15                               9   \n",
       "84                                         15                              13   \n",
       "85                                         15                               0   \n",
       "86                                         15                               0   \n",
       "87                                         14                              34   \n",
       "88                                         14                               0   \n",
       "89                                         13                               0   \n",
       "90                                         12                               9   \n",
       "91                                          9                               9   \n",
       "92                                          9                              67   \n",
       "93                                          9                               0   \n",
       "94                                          9                               0   \n",
       "95                                          8                              20   \n",
       "96                                          8                               0   \n",
       "97                                          8                            5821   \n",
       "98                                          7                               6   \n",
       "99                                          7                              12   \n",
       "100                                         7                               0   \n",
       "101                                         7                               0   \n",
       "102                                         7                               6   \n",
       "103                                         5                               0   \n",
       "\n",
       "     Total Population   latitude   longitude  \n",
       "0             3424400  38.963745   35.243322  \n",
       "1              994383  33.854721   35.862285  \n",
       "2              653031  30.585164   36.238414  \n",
       "3              567507  51.165691   10.451526  \n",
       "4              247057  33.223191   43.679291  \n",
       "5              126688  26.820553   30.802498  \n",
       "6              107145  60.128161   18.643501  \n",
       "7               47825  47.516231   14.550072  \n",
       "8               31519  52.132633    5.291266  \n",
       "9               19506  56.263920    9.501785  \n",
       "10              16956  42.733883   25.485830  \n",
       "11              14692  40.069099   45.038189  \n",
       "12              23319  39.074208   21.824312  \n",
       "13              16831  46.818188    8.227512  \n",
       "14              14914  46.227638    2.213749  \n",
       "15              14007  40.463667   -3.749220  \n",
       "16              11515  60.472024    8.468946  \n",
       "17              11679  12.862807   30.217636  \n",
       "18               9674  55.378051   -3.435973  \n",
       "19              10745  50.503887    4.469936  \n",
       "20              10640  37.090240  -95.712891  \n",
       "21              12859  35.126413   33.429859  \n",
       "22               5314  41.871940   12.567380  \n",
       "23               3782  15.552727   48.516388  \n",
       "24               3901  56.130366 -106.346771  \n",
       "25               2953  31.791702   -7.092620  \n",
       "26               7427 -14.235004  -51.925280  \n",
       "27               2503  61.924110   25.748151  \n",
       "28               2449  45.943161   24.966760  \n",
       "29               1540  35.937496   14.375416  \n",
       "..                ...        ...         ...  \n",
       "74                154  -1.831239  -78.183406  \n",
       "75                 41  -9.189967  -75.015152  \n",
       "76                 62  -0.789275  113.921327  \n",
       "77                 35  25.354826   51.183884  \n",
       "78                 33  47.166000    9.555373  \n",
       "79                 29  30.375321   69.345116  \n",
       "80                 23  23.634501 -102.552784  \n",
       "81                 17  48.669026   19.699024  \n",
       "82                 40  48.019573   66.923684  \n",
       "83                 24   7.369722   12.354722  \n",
       "84                 28  43.915886   17.679076  \n",
       "85                 17  40.143105   47.576927  \n",
       "86                 18        NaN         NaN  \n",
       "87                 48  23.885942   45.079162  \n",
       "88                 14   7.873054   80.771797  \n",
       "89                 13 -16.290154  -63.588653  \n",
       "90                 21        NaN         NaN  \n",
       "91                 18   9.748917  -83.753428  \n",
       "92                 76   9.145000   40.489673  \n",
       "93                 10  11.825138   42.590275  \n",
       "94                  9  17.570692   -3.996166  \n",
       "95                 28        NaN         NaN  \n",
       "96                 12   4.570868  -74.297333  \n",
       "97               5829  28.033886    1.659626  \n",
       "98                 13   6.428055   -9.429499  \n",
       "99                 19   1.373333   32.290275  \n",
       "100                10   9.307690    2.315834  \n",
       "101                 7  17.607789    8.081666  \n",
       "102                13  21.512583   55.923255  \n",
       "103                 5  13.794185  -88.896530  \n",
       "\n",
       "[104 rows x 8 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_nan_df = total_sum_df[pd.notnull(total_sum_df['Country'])]\n",
    "dropped_nan_df = dropped_nan_df.sort_values('Refugees (incl. refugee-like situations)', ascending=False)\n",
    "dropped_nan_df = dropped_nan_df.reset_index()\n",
    "dropped_nan_df = dropped_nan_df.drop(['index'], axis=1)\n",
    "#dropped_nan_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casualty Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VDC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Year-by-Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_bokeh\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# call this so that running plot_bokeh won't create \n",
    "# a new window and results will be shown in notebook\n",
    "pandas_bokeh.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is provincial for VDC, we decided to use the provincial shapefile to map the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the shape file and save it as a geo data frame\n",
    "shp_file = os.path.join('syr_admin_shp_utf8_18219', 'syr_admin1.shp')\n",
    "map_df   = gpd.read_file(shp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the VDC csv file and save it as a pandas data frame\n",
    "dataset = pd.read_csv('vdc_data.csv', encoding='latin-1', dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VDC data set's \"Date of death\" column contains the month, day, and year the person died, but we only wanted to see the yearly fluctuations. Therefore, we took a substring of the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data has month and day, so we took a substring of the year of death\n",
    "dataset['Year of Death'] = dataset['Date of death'].str[:4]\n",
    "\n",
    "# counts the number of times a province is in the dataset for a certain year\n",
    "province_count = dataset.groupby(['Province', 'Year of Death']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns to make data frame smaller\n",
    "simplified_df = province_count.drop(province_count.columns[1:], axis=1)\n",
    "simplified_df = simplified_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns to make data frame smaller\n",
    "simplified_df = province_count.drop(province_count.columns[1:], axis=1)\n",
    "simplified_df = simplified_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slider for Bokeh maps works with column titles, not row values, so we had to pivot the table. The once \"Date of death\" values became column titles and the count of Syrian casualties for that particular year and country became the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it so years are columns rather than values\n",
    "year_as_column = simplified_df.pivot_table('Unnamed: 0', 'Province', 'Year of Death')\n",
    "year_as_column.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping irrelevant years\n",
    "year_as_column = year_as_column.drop(['0000', '1970'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the province names in the VDC data set and the shapefile for Syria were not the same, so we had to go through the names manually and see which ones were different so that we could match the different names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing province names by hand\n",
    "name_change = {\n",
    "    'Damascus Suburbs': 'Rural Damascus',\n",
    "    'Daraa': 'Dar\\'a',\n",
    "    'Deir Ezzor': 'Deir-ez-Zor',\n",
    "    'Hasakeh': 'Al-Hasakeh',\n",
    "    'Idlib': 'Idleb',\n",
    "    'Raqqa': 'Ar-Raqqa',\n",
    "    'Sweida': 'As-Sweida'\n",
    "}\n",
    "\n",
    "# renames the provinces using name_change\n",
    "year_as_column.replace(name_change, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining data from casualties (VDC) and geo data frame (shape file)\n",
    "merged = year_as_column.set_index('Province').join(map_df.set_index('NAME_EN'))\n",
    "merged.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping irrelevant information\n",
    "# row where there were no data for geo data\n",
    "merged = merged.drop([10, 15], axis=0)\n",
    "# columns with information not pertaining to creating choropleth map\n",
    "merged.drop(merged.columns[9:16], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with plot_bokeh() is that it only takes immutable objects. However, the Pandas dataframe is mutable. Therefore, in order to bypass this problem, we decided to convert the Pandas dataframe into a GeoDataFrame. The following code describes that process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas dataframe to GeoDataFrame\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "\n",
    "geometry = merged['geometry']\n",
    "merged_gdf = merged.drop(['geometry'], axis=1)\n",
    "crs = {'init': 'epsg:4326'}\n",
    "gdf = GeoDataFrame(merged_gdf, crs=crs, geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify slider columns:\n",
    "slider_columns = [\"201%d\"%i for i in range(1, 8)]\n",
    "slider_range = range(2011, 2018)\n",
    "\n",
    "# make slider plot:\n",
    "gdf.plot_bokeh(\n",
    "    figsize=(900, 600),\n",
    "    slider=slider_columns,\n",
    "    slider_range=slider_range,\n",
    "    slider_name=\"Year\", \n",
    "    colormap='Inferno',\n",
    "    hovertool_columns=[\"Province\"],\n",
    "    title=\"Deaths in Syria\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Year-by-Year with plotly and mapbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle and read the file\n",
    "import pickle\n",
    "final = pickle.load(open('./death_by_province_by_year.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://plot.ly/python/scattermapbox/\n",
    "# reference: https://community.periscopedata.com/t/36nz2s/plotly-choropleth-with-slider-map-charts-over-time\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "# this is a public mapbox token\n",
    "mapbox_access_token = 'pk.eyJ1IjoibWF0dGhld2lydHoiLCJhIjoiY2p3ZTNpNXlnMHYxcjQ5bzdwMjc0anlpeSJ9.bSLA-SSqEomk0hC52rNliQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first year\n",
    "year = 2011\n",
    "\n",
    "# for every year we need the latitude, longitude, and the # of casualties\n",
    "# we use a for loop to store the data for each year of the Syrian War\n",
    "data_slider = []\n",
    "for year in final['year'].unique():\n",
    "    sect =  final[(final['year']== year)]\n",
    "\n",
    "    for col in sect.columns:\n",
    "        sect[col] = sect[col].astype(str)\n",
    "        \n",
    "    data_each_yr = go.Scattermapbox(\n",
    "        name=str(year),\n",
    "        lat=['36.2021',\n",
    "             '33.5138',\n",
    "             '33.5167',\n",
    "             '32.6264',\n",
    "             '35.3297',\n",
    "             '35.1409',\n",
    "             '36.5079',\n",
    "             '34.7324',\n",
    "             '35.9310',\n",
    "             '33.1219',\n",
    "             '35.5407',  \n",
    "             '35.9594',  \n",
    "             '32.7129', \n",
    "             '34.8959'],\n",
    "        lon=['37.1343',\n",
    "             '36.2765',\n",
    "             '36.9541',\n",
    "             '36.1033',\n",
    "             '40.1350',\n",
    "             '36.7552',\n",
    "             '40.7463',\n",
    "             '36.7137',\n",
    "             '36.6418',\n",
    "             '35.8209',\n",
    "             '35.7953', \n",
    "             '38.9981',  \n",
    "             '36.5663',\n",
    "             '35.8867'],\n",
    "        text=[\"Aleppo\",\n",
    "              \"Damascus\",\n",
    "              \"Rural Damascus\",\n",
    "              \"Daraa\",\n",
    "              \"Deir Ezzor\",\n",
    "              \"Hama\",\n",
    "              \"Hasakeh\",\n",
    "              \"Homs\",\n",
    "              \"Idlib\",\n",
    "              \"Lattakia\",\n",
    "              \"Quneitra\", \n",
    "              \"Ar Raqqah\", \n",
    "              \"As Suwayda\",\n",
    "              \"Tartus\"],\n",
    "        mode='markers',\n",
    "        marker = go.scattermapbox.Marker(\n",
    "            size = sect['casualties'].astype(int),\n",
    "            color = colors[1],\n",
    "            sizemode = 'area',\n",
    "        ), visible=False\n",
    "    )\n",
    "    data_slider.append(data_each_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the steps are for each of the possible places our slider can rest\n",
    "steps = []\n",
    "for i in range(len(data_slider)):\n",
    "    step = dict(method='restyle',\n",
    "                args=['visible', [False] * len(data_slider)],\n",
    "                label='Year {}'.format(i + 2011))\n",
    "    step['args'][1][i] = True\n",
    "    steps.append(step)\n",
    "    \n",
    "sliders = [dict(active=0, pad={\"t\": 1}, steps=steps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets up our frame with the mapbox\n",
    "layout = go.Layout(\n",
    "    showlegend=False,\n",
    "    title = go.layout.Title(\n",
    "            text = '2011-2018 Syrian Casualties'\n",
    "        ),\n",
    "    autosize=True,\n",
    "    hovermode='closest',\n",
    "    sliders=sliders,\n",
    "    mapbox=go.layout.Mapbox(\n",
    "        accesstoken=mapbox_access_token,\n",
    "        bearing=0,\n",
    "        center=go.layout.mapbox.Center(\n",
    "            lat=34.7,\n",
    "            lon=37.2\n",
    "        ),\n",
    "        pitch=0,\n",
    "        zoom=5.4\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "fig = go.Figure(data=data_slider, layout=layout)\n",
    "py.iplot(fig, filename='Multiple-Mapbox.html')\n",
    "# plot(fig, filename='Multiple-Mapbox.html')\n",
    "# use ^ to have the graph open into a seperate tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Day-by-Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>Day-by-Day</b> code is similar to the <b>Year-by-Year</b> code, so we hope the viewer doesn't mind if we have less comments in this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the shape file and save it as a geo data frame\n",
    "shp_file = os.path.join('syr_admin_shp_utf8_18219', 'syr_admin1.shp')\n",
    "map_df   = gpd.read_file(shp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickle objects as a pandas data frame\n",
    "day_df = pickle.load(open('./death_by_province_by_day.pickle', 'rb'))\n",
    "\n",
    "# read the VDC csv file specifically for column \"geometry\"\n",
    "dataset = pd.read_csv('vdc_data.csv', encoding='latin-1', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing province names by hand\n",
    "name_change = {\n",
    "    'Damascus Suburbs': 'Rural Damascus',\n",
    "    'Daraa': 'Dar\\'a',\n",
    "    'Deir Ezzor': 'Deir-ez-Zor',\n",
    "    'Raqqa': 'Ar-Raqqa',\n",
    "    'Sweida': 'As-Sweida',\n",
    "    'Idlib': 'Idleb',\n",
    "    'Hasakeh': 'Al-Hasakeh',\n",
    "}\n",
    "\n",
    "# renames the provinces using name_change\n",
    "day_df.replace(name_change, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it so days are columns rather than values\n",
    "pivoted_df = day_df.pivot_table('casualties','province','day').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the data frames in order to obtain the geo data\n",
    "use = pivoted_df.join(map_df.set_index('NAME_EN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing any unnecessary columns\n",
    "ready = use.drop(columns=['NAM_EN_REF','NAME_AR','PCODE','ADM0_EN','ADM0_AR','ADM0_PCODE','UPDATE_DAT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of days from the first date of death to the last date of death is 2,686 days. Therefore, we created 2,686 columns for each day. (Note: this may take a while to finish running.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the \"year-month-day time\" and replace it with the \"day\"\n",
    "for i in range(0, 2687):\n",
    "    ready = ready.rename(index=str, columns={ready.columns[i]: str(i)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas dataframe to GeoDataFrame\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "\n",
    "geometry = ready['geometry']\n",
    "crs = {'init': 'epsg:4326'}\n",
    "day_gdf = GeoDataFrame(ready, crs=crs, geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 'province' a column\n",
    "day_gdf = day_gdf.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with our visualization is that most of the deaths are in the single to double digits. Very few times do the number of deaths on a single day go into the triple digits. However, the color bar is uniformly split, and we weren't able to find documentation on how to split up the bokeh color bar up, so we brute forced that colors in the color bar.<br><br>\n",
    "What we wanted to display was that between 0 and 100, the difference in hue would be greater than the difference in hue between 101-600. Therefore, there would be a bigger variety of colors on the map at a certain time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify slider columns\n",
    "slider_columns = []\n",
    "for i in range (0, 2687):\n",
    "    slider_columns.append(str(i))\n",
    "\n",
    "slider_range = range(0, 2687)\n",
    "\n",
    "# make slider plot\n",
    "day_gdf.plot_bokeh(\n",
    "    figsize=(900, 600),\n",
    "    slider=slider_columns,\n",
    "    slider_range=slider_range,\n",
    "    slider_name=\"Day\",\n",
    "    # brute force color bar for map\n",
    "    colormap=['#edf8f3', '#dcf2e8', '#cbebdd', '#b9e5d2', '#a8dfc7', '#97d8bc', '#85d2b1', '#74cba6', '#63c59b', '#52bf90',\n",
    "              '#52bf90', '#49ab81', '#419873', '#398564', '#317256', '#295f48', '#204c39', '#18392b', '#18392b', '#18392b', \n",
    "              '#10261c', '#10261c', '#10261c', '#10261c', '#10261c', '#10261c', '#10261c', '#10261c', '#10261c', '#10261c', \n",
    "              '#0a1812', '#0a1812', '#0a1812', '#0a1812', '#0a1812', '#0a1812', '#0a1812', '#0a1812', '#0a1812', '#0a1812',\n",
    "              '#08140f', '#08140f', '#08140f', '#08140f', '#08140f', '#08140f', '#08140f', '#08140f', '#08140f', '#08140f', \n",
    "              '#07110c', '#07110c', '#07110c', '#07110c', '#07110c', '#07110c', '#07110c', '#07110c', '#07110c', '#07110c', \n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', \n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', \n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', \n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', \n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e',\n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e',\n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', \n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e',\n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e',\n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e',\n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', \n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', \n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', \n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', \n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e',\n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e',\n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', \n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e',\n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e',\n",
    "              '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e', '#08130e',\n",
    "    ],\n",
    "    hovertool_columns=[\"province\"],\n",
    "    title=\"Deaths in Syria\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refugee Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly Inflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yearly Refugee Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~hwu43/0 or inside your plot.ly account where it is named 'd3-world-map'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~hwu43/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "\n",
    "\n",
    "data = [go.Choropleth(\n",
    "    locations = dropped_nan_df['CODE'],\n",
    "    z = dropped_nan_df['Refugees (incl. refugee-like situations)'],\n",
    "    text = dropped_nan_df['Country'],\n",
    "    colorscale = [\n",
    "        [0,\"#E1F5FE\"], #50\n",
    "        [0.0001,\"#E1F5FE\"],\n",
    "        [0.0001,'#c4ebfc'],\n",
    "        [0.001,\"#c4ebfc\"], \n",
    "        [0.001,\"#B3E5FC\"], #100\n",
    "        [0.01,\"#B3E5FC\"],\n",
    "        [0.01,\"#81D4FA\"], #200\n",
    "        [0.1,\"#81D4FA\"],\n",
    "        [0.1,\"#4FC3F7\"], #300\n",
    "        [0.2,\"#4FC3F7\"],\n",
    "        [0.2,\"#29B6F6\"], #400\n",
    "        [0.3,\"#29B6F6\"],\n",
    "        [0.3,\"#03A9F4\"], #500\n",
    "        [0.4,\"#03A9F4\"],\n",
    "        [0.4,\"#039BE5\"], #600\n",
    "        [0.5,\"#039BE5\"],\n",
    "        [0.5,\"#0288D1\"], #700\n",
    "        [0.6,\"#0288D1\"],\n",
    "        [0.6,\"#0277BD\"], #800\n",
    "        [0.7,\"#0277BD\"], \n",
    "        [0.7,\"#01579B\"], #900\n",
    "        [0.8,\"#01579B\"], \n",
    "        [0.8,\"#00457c\"], #1000\n",
    "        [0.9,\"#00457c\"],\n",
    "        [0.9,\"#002f56\"], #1100\n",
    "        [1.0,\"#002f56\"],  \n",
    "    ],\n",
    "       \n",
    "    zmin = 0,\n",
    "    #zmax = 600000,\n",
    "    zmax = 1000000,\n",
    "    autocolorscale = False,\n",
    "    reversescale = False,\n",
    "    marker = go.choropleth.Marker(\n",
    "        line = go.choropleth.marker.Line(\n",
    "            color = 'rgb(180,180,180)',\n",
    "            width = 0.5\n",
    "        )),\n",
    "    colorbar = go.choropleth.ColorBar(\n",
    "        tickprefix = '',\n",
    "        title = 'Number of Syrian Refugees'),\n",
    "\n",
    "\n",
    ")]\n",
    "\n",
    "# following code is for lines connecting countries\n",
    "countries = [go.Scattergeo(\n",
    "    lon = total_sum_df['longitude'],\n",
    "    lat = total_sum_df['latitude'],\n",
    "    hoverinfo = 'text',\n",
    "    text = total_sum_df['Country'],\n",
    "    mode = 'none',\n",
    "#     marker = go.scattergeo.Marker(\n",
    "#         size = 0,\n",
    "#         color = 'rgb(255, 0, 0)',\n",
    "#         line = go.scattergeo.marker.Line(\n",
    "#             width = 3,\n",
    "#             color = 'rgba(68, 68, 68, 0)'\n",
    "#         ))\n",
    "    )]\n",
    "\n",
    "refugee_paths = []\n",
    "\n",
    "syria_start_lon = 38.996815\n",
    "syria_start_lat = 34.802075\n",
    "maximum_value = float(dropped_nan_df['Refugees (incl. refugee-like situations)'].max())\n",
    "# print(dropped_nan_df)\n",
    "for i in range(len(dropped_nan_df)):\n",
    "    # setting the opacity of the lines\n",
    "    opacity = 0\n",
    "    country_refugee = dropped_nan_df['Refugees (incl. refugee-like situations)'][i]\n",
    "    opacity = float(country_refugee) / maximum_value\n",
    "    # doing this because otherwise, the lines to countries besides Germany are invisible\n",
    "    if opacity < 0.25:\n",
    "        opacity = 0.25\n",
    "        \n",
    "    refugee_paths.append(\n",
    "        go.Scattergeo(\n",
    "            locationmode = 'country names',\n",
    "            lon = [syria_start_lon, dropped_nan_df['longitude'][i]],\n",
    "            lat = [syria_start_lat, dropped_nan_df['latitude'][i]],\n",
    "            mode = 'lines',\n",
    "            line = go.scattergeo.Line(\n",
    "                width = 1,\n",
    "                color = 'red',\n",
    "            ),\n",
    "            opacity = opacity,\n",
    "        )\n",
    "    )\n",
    "\n",
    "layout = go.Layout(\n",
    "    showlegend = False,\n",
    "    title = go.layout.Title(\n",
    "        text = '2011-2018 Syrian Refugee Migration Patterns'\n",
    "    ),\n",
    "    \n",
    "    geo = go.layout.Geo(\n",
    "        showframe = False,\n",
    "        showcoastlines = False,\n",
    "        projection = go.layout.geo.Projection(\n",
    "            type = 'equirectangular',\n",
    "        ),\n",
    "        showland = True,\n",
    "        landcolor = 'rgb(243, 243, 243)',\n",
    "        countrycolor = 'rgb(204, 204, 204)', \n",
    "    ),\n",
    "    \n",
    "    annotations = [go.layout.Annotation(\n",
    "        x = 0.55,\n",
    "        y = 0.1,\n",
    "        xref = 'paper',\n",
    "        yref = 'paper',\n",
    "        text = 'Source: <a href=\"http://popstats.unhcr.org/en/asylum_seekers_monthly\">\\\n",
    "            Asylum-Seekers (Monthly Data)</a>',\n",
    "        showarrow = False\n",
    "    )]\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = data +refugee_paths , layout = layout)\n",
    "py.iplot(fig, validate = False, filename = 'd3-world-map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
